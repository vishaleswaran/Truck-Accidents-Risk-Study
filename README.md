# Truck-Accidents-Risk-Study
Project Objective

By using the Cloudera Hadoop tools and techniques, we will process the data to create our own analytics reports and create a visual presentation that will benefit decision-makers.
Big Data Hadoop Ecosystems will use truck fleet data to refine and analyze trucking movement to meet the organizational goal of better understanding risk. The use case involves geographic data, vehicles, average mileage, gas consumption, events, risk factors, and other supporting information.
Each truck has been equipped to with devices to log location and event data. These events are streamed back to a datacenter where we will process the data and revise truck movements to increase safety.

Business Objective

Accidents caused by large trucks remain one of the leading causes of injuries and deaths in the United States. The objective is identifying dangerous commercial truck drivers nationwide.
Upon completing this study, we will be able to answer common business questions related to the trucking business, such as:
Which truck has the highest risk factor based on geographic location and time?

Task 1: Loading Data into Hadoop File System (HDFS)

Objectives 

In this exercise, we will load the geographic data we created in your local machine into HDFS, which is in Cloudera VM. We can perform tasks like create directories, navigate file systems, and upload files to HDFS. In addition, we will perform a few other HIVE related tables loading tasks. 
Outlines 
1.	Transfer your input files into Cloudera VM by utilizing the system copy command. 
2.	Create a Hive Table for geolocation tab and load data from Geolocation file.
3.  Loaded the imported file into HIVE by utilizing “LOAD DATA INPATH”.




